import os
import json
import traceback
import google.generativeai as genai
from dotenv import load_dotenv

# services klasÃ¶rÃ¼nden import
from services import calculator, search

# Ortam deÄŸiÅŸkenlerini yÃ¼kle (.env)
load_dotenv()

# Gemini client baÅŸlat
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))


class WebChatbot:
    def __init__(self):
        # BaÅŸlangÄ±Ã§ sistem mesajÄ± (asistanÄ±n rolÃ¼nÃ¼ tanÄ±mlar)
        self.system_prompt = """Sen yardÄ±mcÄ± bir asistansÄ±n. KullanÄ±cÄ±nÄ±n sorularÄ±nÄ± yanÄ±tla, gerektiÄŸinde hesaplama yap ve Wikipedia'dan bilgi ara.

Ã–NEMLI: CevaplarÄ±nÄ± mutlaka Markdown formatÄ±nda ver. Åu kurallarÄ± takip et:

- BaÅŸlÄ±klar iÃ§in # ## ### kullan
- Ã–nemli metinler iÃ§in **kalÄ±n** yazÄ± kullan
- Listeler iÃ§in - veya 1. kullan
- Kod parÃ§alarÄ± iÃ§in `kod` veya ```kod bloÄŸu``` kullan
- BÃ¶lÃ¼mleri net baÅŸlÄ±klarla ayÄ±r
- Uzun cevaplarda alt baÅŸlÄ±klar kullan
"""

        # Sohbet geÃ§miÅŸini baÅŸlat
        self.history = []
        self.messages = []

        # KullanÄ±cÄ±ya ait ek veriler
        self.user_data = {
            "calculations": [],
            "notes": [],
        }

        # Maksimum tutulacak mesaj sayÄ±sÄ± (kayan pencere)
        self.MAX_HISTORY = 15

        # Gemini modelini baÅŸlat
        self.model = genai.GenerativeModel('gemini-1.5-flash')

    # Fonksiyon tanÄ±mlarÄ±nÄ± dÃ¶ndÃ¼rÃ¼r (hesaplama ve arama)
    def get_tools(self):
        return [
            {
                "function_declarations": [calculator.get_function_def()]
            },
            {
                "function_declarations": [search.get_function_def()]
            }
        ]

    # Sohbet geÃ§miÅŸini sÄ±fÄ±rlar (kullanÄ±cÄ± "geÃ§miÅŸi temizle" dediÄŸinde kullanÄ±labilir)
    def reset_history(self):
        self.history = []
        self.messages = []

    # Mesaj geÃ§miÅŸini kÄ±saltÄ±r
    def _get_limited_history(self):
        return self.messages[-self.MAX_HISTORY:]

    # KullanÄ±cÄ± mesajÄ±nÄ± iÅŸler ve modeli stream halinde Ã§aÄŸÄ±rÄ±r
    def chat_stream(self, user_message):
        try:
            # KullanÄ±cÄ± mesajÄ±nÄ± geÃ§miÅŸe ekle
            self.messages.append({"role": "user", "parts": [{"text": user_message}]})
            print(f"ğŸ“ KullanÄ±cÄ± mesajÄ±: {user_message}")

            # Gemini'yi Ã§aÄŸÄ±r
            chat = self.model.start_chat(history=self._get_limited_history())
            
            # Tools/fonksiyonlarÄ± ekle
            response = chat.send_message(
                user_message,
                tools=self.get_tools(),
                stream=True
            )

            full_content = ""
            function_calls = []

            # Response'u stream et
            for chunk in response:
                if chunk.candidates and chunk.candidates[0].content:
                    content = chunk.candidates[0].content.parts[0].text
                    if content:
                        full_content += content
                        yield {"type": "content", "content": content}
                
                # Fonksiyon Ã§aÄŸrÄ±larÄ±nÄ± kontrol et
                if (chunk.candidates and chunk.candidates[0].content and 
                    chunk.candidates[0].content.parts and 
                    hasattr(chunk.candidates[0].content.parts[0], 'function_call')):
                    
                    function_call = chunk.candidates[0].content.parts[0].function_call
                    fn_name = function_call.name
                    args = {k: v for k, v in function_call.args.items()}
                    
                    function_calls.append((fn_name, args))
                    yield {"type": "function_call", "function": fn_name, "args": args}

            # Fonksiyon Ã§aÄŸrÄ±larÄ±nÄ± iÅŸle
            if function_calls:
                for fn_name, args in function_calls:
                    print(f"ğŸ”§ Fonksiyon Ã§aÄŸrÄ±sÄ±: {fn_name} - {args}")
                    
                    # FonksiyonlarÄ± Ã§alÄ±ÅŸtÄ±r
                    if fn_name == "search_info":
                        result = search.search_info(**args)
                    elif fn_name == "calculate":
                        result = calculator.calculate(**args, user_data=self.user_data)
                    else:
                        result = {"error": f"Bilinmeyen fonksiyon: {fn_name}"}
                    
                    yield {"type": "function_result", "result": result}

                    # Fonksiyon sonucunu geÃ§miÅŸe ekle
                    self.messages.append({
                        "role": "function",
                        "parts": [{
                            "function_response": {
                                "name": fn_name,
                                "response": result
                            }
                        }]
                    })

                    # Fonksiyon sonucu ile tekrar Ã§aÄŸÄ±r
                    follow_up_response = chat.send_message(
                        f"Fonksiyon sonucu: {result}",
                        stream=True
                    )

                    # Follow-up response'u stream et
                    follow_up_content = ""
                    for follow_chunk in follow_up_response:
                        if follow_chunk.candidates and follow_chunk.candidates[0].content:
                            content = follow_chunk.candidates[0].content.parts[0].text
                            if content:
                                follow_up_content += content
                                yield {"type": "content", "content": content}

                    # Asistan cevabÄ±nÄ± geÃ§miÅŸe ekle
                    if follow_up_content:
                        self.messages.append({"role": "model", "parts": [{"text": follow_up_content}]})
            else:
                # Normal cevabÄ± geÃ§miÅŸe ekle (fonksiyon Ã§aÄŸrÄ±sÄ± yoksa)
                if full_content:
                    self.messages.append({"role": "model", "parts": [{"text": full_content}]})

            # Stream sonu
            yield {"type": "end"}

        except Exception as e:
            print("ğŸ”¥ chat_stream hatasÄ±:", traceback.format_exc())
            yield {"type": "error", "error": str(e), "trace": traceback.format_exc()}