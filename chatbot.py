import os
import json
import traceback
from openai import OpenAI
from dotenv import load_dotenv

# services klasÃ¶rÃ¼nden import
from services import calculator, search

# Ortam deÄŸiÅŸkenlerini yÃ¼kle (.env)
load_dotenv()

# OpenAI client baÅŸlat
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


class WebChatbot:
    def __init__(self):
        # BaÅŸlangÄ±Ã§ sistem mesajÄ± (asistanÄ±n rolÃ¼nÃ¼ tanÄ±mlar)
        self.system_prompt = {
            "role": "system",
            "content": """Sen yardÄ±mcÄ± bir asistansÄ±n. KullanÄ±cÄ±nÄ±n sorularÄ±nÄ± yanÄ±tla, gerektiÄŸinde hesaplama yap ve Wikipedia'dan bilgi ara.

Ã–NEMLI: CevaplarÄ±nÄ± mutlaka Markdown formatÄ±nda ver. Åu kurallarÄ± takip et:

- BaÅŸlÄ±klar iÃ§in # ## ### kullan
- Ã–nemli metinler iÃ§in **kalÄ±n** yazÄ± kullan
- Listeler iÃ§in - veya 1. kullan
- Kod parÃ§alarÄ± iÃ§in `kod` veya ```kod bloÄŸu``` kullan
- BÃ¶lÃ¼mleri net baÅŸlÄ±klarla ayÄ±r
- Uzun cevaplarda alt baÅŸlÄ±klar kullan
"""
        }

        # Sohbet geÃ§miÅŸini baÅŸlat (sadece sistem mesajÄ± ile)
        self.messages = [self.system_prompt]

        # KullanÄ±cÄ±ya ait ek veriler
        self.user_data = {
            "calculations": [],
            "notes": [],
        }

        # Maksimum tutulacak mesaj sayÄ±sÄ± (kayan pencere)
        self.MAX_HISTORY = 15

    # Fonksiyon tanÄ±mlarÄ±nÄ± dÃ¶ndÃ¼rÃ¼r (hesaplama ve arama)
    def get_functions(self):
        return [
            calculator.get_function_def(),
            search.get_function_def()
        ]

    # Sohbet geÃ§miÅŸini sÄ±fÄ±rlar (kullanÄ±cÄ± "geÃ§miÅŸi temizle" dediÄŸinde kullanÄ±labilir)
    def reset_history(self):
        self.messages = [self.system_prompt]

    # Mesaj geÃ§miÅŸini kÄ±saltÄ±r (sadece sistem mesajÄ± + son N mesaj)
    def _get_limited_history(self):
        # Sistem mesajÄ±nÄ± koru, sadece son N mesajÄ± ekle
        return [self.system_prompt] + self.messages[-self.MAX_HISTORY:]

    # KullanÄ±cÄ± mesajÄ±nÄ± iÅŸler ve modeli stream halinde Ã§aÄŸÄ±rÄ±r
    def chat_stream(self, user_message):
        try:
            # KullanÄ±cÄ± mesajÄ±nÄ± geÃ§miÅŸe ekle
            self.messages.append({"role": "user", "content": user_message})
            print(f"ğŸ“ KullanÄ±cÄ± mesajÄ±: {user_message}")

            # Modeli Ã§aÄŸÄ±rÄ±rken sadece sÄ±nÄ±rlÄ± geÃ§miÅŸi gÃ¶nder
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=self._get_limited_history(),
                functions=self.get_functions(),
                function_call="auto"
            )

            message = response.choices[0].message

            # Fonksiyon Ã§aÄŸrÄ±sÄ± var mÄ± kontrol et
            if hasattr(message, 'function_call') and message.function_call:
                fn_name = message.function_call.name
                args = json.loads(message.function_call.arguments)

                print(f"ğŸ”§ Fonksiyon Ã§aÄŸrÄ±sÄ±: {fn_name} - {args}")
                yield {"type": "function_call", "function": fn_name, "args": args}

                # FonksiyonlarÄ± Ã§alÄ±ÅŸtÄ±r
                if fn_name == "search_info":
                    result = search.search_info(**args)
                    yield {"type": "function_result", "result": result}

                elif fn_name == "calculate":
                    result = calculator.calculate(**args, user_data=self.user_data)
                    yield {"type": "function_result", "result": result}

                # Fonksiyon sonucunu geÃ§miÅŸe ekle
                self.messages.append({
                    "role": "function",
                    "name": fn_name,
                    "content": json.dumps(result, ensure_ascii=False)
                })

                # Streaming cevap al
                stream = client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=self._get_limited_history(),
                    stream=True
                )

                full_content = ""
                for chunk in stream:
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        full_content += content
                        yield {"type": "content", "content": content}

                # Tam cevabÄ± geÃ§miÅŸe ekle
                self.messages.append({"role": "assistant", "content": full_content})

            else:
                # Normal cevap (fonksiyon Ã§aÄŸrÄ±sÄ± yok)
                stream = client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=self._get_limited_history(),
                    stream=True
                )

                full_content = ""
                for chunk in stream:
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        full_content += content
                        yield {"type": "content", "content": content}

                # Tam cevabÄ± geÃ§miÅŸe ekle
                self.messages.append({"role": "assistant", "content": full_content})

            # Stream sonu
            yield {"type": "end"}

        except Exception as e:
            print("ğŸ”¥ chat_stream hatasÄ±:", traceback.format_exc())
            yield {"type": "error", "error": str(e), "trace": traceback.format_exc()}
